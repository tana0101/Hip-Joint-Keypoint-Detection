# åŸºæ–¼æ·±åº¦å­¸ç¿’çš„é«–é—œç¯€é—œéµé»åµæ¸¬ç³»çµ±

<div align="center">
  <div>
    <a href="https://github.com/tana0101/Hip-Joint-Keypoint-Detection/README_zh_TW.md">ğŸ‡¹ğŸ‡¼ç¹é«”ä¸­æ–‡</a> |
    <a href="https://github.com/tana0101/Hip-Joint-Keypoint-Detection/README.md">ğŸŒEnglish</a> |
    <a href="https://deepwiki.com/tana0101/Hip-Joint-Keypoint-Detection">ğŸ“šDeepWiki</a> |
    <a href="https://github.com/tana0101/Hip-Joint-Keypoint-Detection/issues">â“issues</a> |
    <a href="">ğŸ“Paper(å°šæœªç™¼è¡¨)</a>
  </div>
<br>
  <img src="src/img/project_banner.png" style="width: 70%;"/>
<br>

</div>

æœ¬å°ˆæ¡ˆæå‡ºä¸€å¥—**åŸºæ–¼æ·±åº¦å­¸ç¿’çš„é«–é—œç¯€é—œéµé»åµæ¸¬ç³»çµ±**ï¼Œç›®çš„åœ¨å”åŠ©é†«ç™‚å°ˆæ¥­äººå“¡é€²è¡Œ**å°å…’é«–é—œç¯€ç™¼è‚²ä¸è‰¯ï¼ˆDevelopmental Dysplasia of the Hip, DDHï¼‰**ä¹‹æ—©æœŸè¨ºæ–·èˆ‡æ²»ç™‚è¦åŠƒï¼Œé™ä½äººç‚ºåˆ¤è®€èª¤å·®ï¼Œä¸¦æå‡è‡¨åºŠé‡æ¸¬çš„ä¸€è‡´æ€§èˆ‡æ•ˆç‡ã€‚

## Introduction

å°å…’é«–é—œç¯€ç™¼è‚²ä¸è‰¯ï¼ˆDDHï¼‰æ˜¯ä¸€ç¨®å¸¸è¦‹ä½†å®¹æ˜“è¢«å¿½ç•¥çš„éª¨éª¼ç™¼è‚²ç–¾ç—…ï¼Œè‹¥æœªèƒ½åŠæ—©è¨ºæ–·èˆ‡ä»‹å…¥ï¼Œå¯èƒ½å°å­©ç«¥æœªä¾†çš„è¡Œèµ°èƒ½åŠ›èˆ‡éª¨éª¼ç™¼è‚²é€ æˆé•·æœŸå½±éŸ¿ã€‚

åœ¨è‡¨åºŠå¯¦å‹™ä¸Šï¼ŒDDH çš„è¨ºæ–·é«˜åº¦ä»°è³´é†«å¸«å° X å…‰å½±åƒçš„äººå·¥åˆ¤è®€èˆ‡é‡æ¸¬ï¼Œéç¨‹å…·æœ‰ä¸€å®šçš„ä¸»è§€æ€§ï¼Œä¸”åœ¨ä¸åŒé†«å¸«æˆ–ä¸åŒæ™‚é–“é»ä¹‹é–“ï¼Œå®¹æ˜“ç”¢ç”Ÿé‡æ¸¬å·®ç•°ã€‚

è¿‘å¹´ä¾†ï¼Œæ·±åº¦å­¸ç¿’åœ¨é†«å­¸å½±åƒåˆ†æé ˜åŸŸå±•ç¾å‡ºå“è¶Šçš„è¡¨ç¾ï¼Œç‰¹åˆ¥é©åˆæ‡‰ç”¨æ–¼é—œéµé»åµæ¸¬ã€è§’åº¦é‡æ¸¬èˆ‡ç–¾ç—…åˆ†ç´šç­‰ä»»å‹™ã€‚æœ¬å°ˆæ¡ˆå³åˆ©ç”¨æ·±åº¦å­¸ç¿’æ¨¡å‹ï¼Œè‡ªå‹•åµæ¸¬é«–é—œç¯€é—œéµé»ï¼Œé€²ä¸€æ­¥è¼”åŠ©è‡¨åºŠé€²è¡Œ DDH ç›¸é—œæŒ‡æ¨™çš„è¨ˆç®—èˆ‡åˆ†é¡ã€‚

## Key Features

- **é«–é—œç¯€é—œéµé»åµæ¸¬**ï¼šè‡ªå‹•é æ¸¬é«–é—œç¯€é—œéµé»åº§æ¨™ã€‚
- **è‡¨åºŠæŒ‡æ¨™é‡æ¸¬**ï¼šæ”¯æ´ Acetabular Index (AI) Angle è¨ˆç®—èˆ‡ IHDI åˆ†é¡ã€‚
- **å¤šæ¨¡å‹æ¶æ§‹æ”¯æ´**ï¼šå¯å½ˆæ€§é¸æ“‡ä¸åŒ Backboneï¼ˆå¦‚ ConvNeXtã€HRNetã€EfficientNet ç­‰ï¼‰ã€‚
- **å¤šç¨® Head è¨­è¨ˆ**ï¼šæ”¯æ´ Direct Regression èˆ‡ SimCC ç³»åˆ—ç­‰ä¸åŒé—œéµé»é æ¸¬ç­–ç•¥ã€‚
- **æ¨¡çµ„åŒ–è¨­è¨ˆ**ï¼šæ–¹ä¾¿é€²è¡Œæ¨¡å‹æ›¿æ›ã€å¯¦é©—æ¯”è¼ƒèˆ‡æ“´å……ç ”ç©¶ã€‚

## Dataset

- è³‡æ–™å­˜æ”¾æ–¼ `dataset/` ç›®éŒ„ä¸­ã€‚
- æ¨™è¨»ç¨‹å¼ä½æ–¼ `Keypoint-Annotation-Tool/` ç›®éŒ„ä¸­ã€‚
ğŸš§ **è³‡æ–™é›†ä¸‹è¼‰èˆ‡æ•´ç†æµç¨‹å°‡æ–¼å¾ŒçºŒè£œå……** ğŸš§

### xray_IHDIï¼ˆä¸»è¦å¯¦é©—è³‡æ–™é›†ï¼‰
<img src="src/img/sample_IHDI.jpg" style="width: 30%;"/>

æœ¬ç ”ç©¶æ¡ç”¨å›æº¯æ€§è³‡æ–™ï¼Œæ”¶é›†ä¾†è‡ªæˆå¤§é†«é™¢æ–¼ 2015 å¹´ 1 æœˆ 1 æ—¥è‡³ 2025 å¹´ 1 æœˆ 19 æ—¥æœŸé–“ï¼Œæ¥å—é«–éƒ¨è¶…éŸ³æ³¢æª¢æŸ¥ä¹‹ 4 æ­²ä»¥ä¸‹å¬°å¹¼å…’ä¹‹ X å…‰å½±åƒè³‡æ–™ã€‚å…±ç´å…¥ 622 ä»½ X å…‰å½±åƒï¼Œå½±åƒå…§å®¹æ¶µè“‹é«–é—œç¯€ç™¼è‚²æ­£å¸¸èˆ‡ç™¼è‚²ä¸è‰¯ä¹‹å€‹æ¡ˆã€‚æ¯å¼µå½±åƒå‡ç¶“è‡¨åºŠå°ˆæ¥­é†«å¸«æ‰‹å‹•æ¨™è¨»åäºŒå€‹é—œéµé»ï¼Œä½œç‚ºå¾ŒçºŒæ¨¡å‹è¨“ç·´ä¹‹æ¨™ç±¤ã€‚

- æ¯å¼µåœ–ç‰‡å°æ‡‰ä¸€å€‹æ¨™è¨» `.csv` æª”æ¡ˆï¼Œå…§å®¹é¡ä¼¼ï¼š
```
"(x1,y1)","(x2,y2)",...,"(x12,y12)"
```

- è³‡æ–™ä¾†æºï¼šæˆå¤§é†«é™¢
- è³‡æ–™é‡ï¼š557 å¼µé«–é—œç¯€ X å…‰å½±åƒï¼ˆå·²æ’é™¤ç•°å¸¸å€¼ï¼‰
- æ¨™è¨»å…§å®¹ï¼š
  - 12 å€‹é«–é—œç¯€é—œéµé»
  - LeftHip / RightHip ç‰©ä»¶æ¨™ç±¤
- å‚™è¨»ï¼šåŸºæ–¼é†«ç™‚è³‡æ–™ä¿è­·èˆ‡éš±ç§è¦ç¯„ï¼Œ**ç„¡æ³•å…¬é–‹é‡‹å‡º**


### MTDDHï¼ˆå…¬é–‹è³‡æ–™é›†ï¼‰
<img src="src/img/sample_MTDDH.jpg" style="width: 30%;"/>

- è³‡æ–™ä¾†æºï¼š[open-hip-dysplasia](https://github.com/radoss-org/open-hip-dysplasia.git)
- è³‡æ–™é‡ï¼š1751 å¼µé«–é—œç¯€ X å…‰å½±åƒï¼ˆå·²æ’é™¤ç•°å¸¸å€¼ï¼‰
- æ¨™è¨»å…§å®¹ï¼š
  - 8 å€‹é«–é—œç¯€é—œéµé»
  - LeftHip / RightHip ç‰©ä»¶æ¨™ç±¤

### è³‡æ–™çµ±è¨ˆåˆ†ä½ˆ

**Acetabular Index (AI) åˆ†ä½ˆ**
<img src="dataset/xray_IHDI_AI_Distribution.png" />
<img src="dataset/mtddh_xray_2d_AI_Distribution.png" />

**IHDI åˆ†é¡åˆ†ä½ˆ**
<div style="display: flex; justify-content: space-between; gap: 10px;">
  <img src="dataset/xray_IHDI_IHDI_Distribution.png" style="width: 49%;" />
  <img src="dataset/mtddh_xray_2d_IHDI_Distribution.png" style="width: 49%;" />
</div>

## Methodology

æœ¬å°ˆæ¡ˆæ¡ç”¨å…©éšæ®µæ–¹æ³•é€²è¡Œé«–é—œç¯€é—œéµé»åµæ¸¬ï¼š
1. **ç‰©ä»¶åµæ¸¬éšæ®µ**ï¼šä½¿ç”¨ YOLO æ¨¡å‹
2. **é—œéµé»åµæ¸¬éšæ®µ**ï¼šä½¿ç”¨å¤šç¨® Backbone èˆ‡ Head æ¶æ§‹çš„æ·±åº¦å­¸ç¿’æ¨¡å‹

### Head Architecture

<img src="src/img/head_design.png" />

æœ¬å°ˆæ¡ˆæ”¯æ´å¤šç¨®é—œéµé» Head è¨­è¨ˆï¼Œä»¥å› æ‡‰ä¸åŒæ¨¡å‹ç‰¹æ€§èˆ‡å¯¦é©—éœ€æ±‚ï¼š

- **SimCC 2D / SimCC 2D Deconv**  
  å±¬æ–¼å®˜æ–¹ SimCC ç³»åˆ—æ–¹æ³•ï¼Œå°‡é—œéµé»åº§æ¨™å›æ­¸å•é¡Œè½‰æ›ç‚ºå…©å€‹ä¸€ç¶­åˆ†é¡å•é¡Œï¼Œåˆ†åˆ¥é æ¸¬ x è»¸èˆ‡ y è»¸çš„é›¢æ•£ä½ç½®æ©Ÿç‡åˆ†ä½ˆï¼Œä¸¦é€é soft-argmax è¨ˆç®—æœ€çµ‚åº§æ¨™ã€‚

- **SimCC 1Dï¼ˆè‡ªè¨‚è®Šé«”ï¼‰**  
  ç‚ºæœ¬ç ”ç©¶è‡ªè¡Œè¨­è¨ˆçš„ SimCC è®Šé«”ï¼Œé€é Global Average Pooling å°‡ç‰¹å¾µåœ–å£“ç¸®ç‚ºä¸€ç¶­å‘é‡ï¼Œä¸¦ä½¿ç”¨å…¨é€£æ¥å±¤é æ¸¬ x èˆ‡ y è»¸çš„ä½ç½®æ©Ÿç‡åˆ†ä½ˆï¼Œä»¥é™ä½æ¨¡å‹è¤‡é›œåº¦ã€‚

- **Direct Regression**  
  å‚³çµ±é—œéµé»å›æ­¸æ–¹æ³•ï¼Œç›´æ¥ä»¥å…¨é€£æ¥å±¤è¼¸å‡ºé—œéµé»çš„ xã€y åº§æ¨™ã€‚

### Backbone Architecture

ç›®å‰æ”¯æ´çš„ Backbone æ¶æ§‹å¦‚ä¸‹ï¼š

- ConvNeXtV1  
  - `ConvNeXtSmallCustom`
- ConvNeXtV1 + Feature Pyramid Networkï¼ˆå¤šå°ºåº¦ç‰¹å¾µï¼‰  
  - `ConvNeXtSmallMS`
- HRNet  
  - `HRNetW32Custom`
  - `HRNetW48Custom`

å…¶ä¸­ `Custom` çµå°¾ä»£è¡¨æœ¬å°ˆæ¡ˆåŸºæ–¼å®˜æ–¹å¯¦ä½œé€²è¡Œä¿®æ”¹èˆ‡å„ªåŒ–ï¼Œä»¥æ›´ç¬¦åˆé«–é—œç¯€é—œéµé»åµæ¸¬ä»»å‹™çš„éœ€æ±‚ã€‚

ğŸš§ **å…¶ä»– Backboneï¼ˆå¦‚ EfficientNetã€InceptionNeXt ç­‰ï¼‰ç›®å‰ä»åœ¨é–‹ç™¼èˆ‡æ¸¬è©¦ä¸­ï¼Œä»¥ç¢ºä¿å¯èˆ‡ä¸åŒ Head æ¶æ§‹ç›¸å®¹** ğŸš§

### Other Techniques

- **Data Augmentation**
  - Random Rotation
  - Random Translation
- **Loss Functions**
  - Direct Regressionï¼šæ‰€æœ‰é»èˆ‡ä¸­å¿ƒé»çš„ MSE Loss
    \[
    L_{MSE} = \frac{1}{N} \sum_{i=1}^{N} \left( (x_i - \hat{x}_i)^2 + (y_i - \hat{y}_i)^2 \right)
    \]
  - SimCC ç³»åˆ—ï¼šKL Divergence Loss
    \[
    L_{KL} = \frac{1}{N} \sum_{i=1}^{N} \left( D_{KL}(P_{x_i} || \hat{P}_{x_i}) + D_{KL}(P_{y_i} || \hat{P}_{y_i}) \right)
    \]
- **Optimizers**
  - AdamW
- **Learning Rate Schedulers**
  - Cosine Annealing
  - Warmup

## Installation

æŒ‰ç…§ä»¥ä¸‹æ–¹å¼å®‰è£æ‰€éœ€çš„ Python ç’°å¢ƒèˆ‡å¥—ä»¶ï¼Œæˆ–æ˜¯ç›´æ¥åŸ·è¡Œå†è£œä¸Šç¼ºå°‘çš„å¥—ä»¶ã€‚

### ä½¿ç”¨ Conda å‰µå»ºè™›æ“¬ç’°å¢ƒ

1. è¤‡è£½å°ˆæ¡ˆï¼š
```
   git clone https://github.com/tana0101/Hip-Joint-Keypoint-Detection.git
   cd Hip-Joint-Keypoint-Detection
```
2. å‰µå»ºä¸¦å•Ÿå‹• Conda è™›æ“¬ç’°å¢ƒï¼š
```
   conda create -n hip_joint_detection python=3.10
   conda activate hip_joint_detection
```
3. å®‰è£æ‰€éœ€å¥—ä»¶ï¼š
```
   pip install -r requirements.txt
```

### ä½¿ç”¨ä¸€èˆ¬ Python ç’°å¢ƒ

1. è¤‡è£½å°ˆæ¡ˆï¼š
```
   git clone https://github.com/tana0101/Hip-Joint-Keypoint-Detection.git
   cd Hip-Joint-Keypoint-Detection
```
2. å®‰è£æ‰€éœ€å¥—ä»¶ï¼š
```
   pip install -r requirements.txt
```

## Usage-Onefold Training & Evaluation

### Split Dataset

ä½¿ç”¨æ–¹å¼ï¼š
```
usage: split.py [-h] --dataset DATASET [--out OUT] [--train TRAIN] [--val VAL]
                [--test TEST] [--seed SEED]

Split dataset into train/val/test with multiple modalities and emit
Ultralytics data.yaml

options:
  -h, --help         show this help message and exit
  --dataset DATASET  Root directory of the dataset, e.g., dataset/xray_IHDI_5
  --out OUT          Output root directory (default: data)
  --train TRAIN      Train split ratio (default: 0.8)
  --val VAL          Validation split ratio (default: 0.1)
  --test TEST        Test split ratio (default: 0.1)
  --seed SEED        Random seed (default: 42)
```

ç¯„ä¾‹åŸ·è¡Œï¼š
```
python split.py --dataset dataset/xray_IHDI_6 --out data --train 0.8 --val 0.1 --test 0.1 --seed 42
```

å°‡æœƒåˆ†å‰²å‡º `data/train`ã€`data/val`ã€`data/test` ä¸‰å€‹å­ç›®éŒ„ï¼Œä¸¦ç”¢ç”Ÿç‰©ä»¶åµæ¸¬ç”¨çš„ `data/data.yaml` æª”æ¡ˆä¾›å¾ŒçºŒè¨“ç·´ä½¿ç”¨ã€‚

### Training

ç”±æ–¼æœ¬å°ˆæ¡ˆæ¡ç”¨å…©éšæ®µï¼Œå…ˆä½¿ç”¨ YOLO åµæ¸¬ä¸¦è£åˆ‡å‡ºé«–é—œç¯€å€åŸŸï¼Œå†é€²è¡Œå–®é‚Šé—œéµé»åµæ¸¬æ¨¡å‹çš„è¨“ç·´ã€‚

#### Step 1: Train YOLO Detector

ä½¿ç”¨æ–¹å¼ï¼š
```
python train_yolo.py \
  --model yolo12s.pt \
  --data data/data.yaml \
  --epochs 300 --imgsz 640 --batch 8 --device 0 \
  --project runs/train --name yolo12s --pretrained --seed 42 \
  --fliplr 0.0 --flipud 0.0 --degrees 5.0 \
  --shear 0.0 --perspective 0.0 --mosaic 0.0 --mixup 0.0
```

#### Step 2: Train Keypoint Detector

ä½¿ç”¨æ–¹å¼ï¼š
```
usage: train_hip_crop_keypoints.py [-h] --data_dir DATA_DIR --model_name
                                   MODEL_NAME [--epochs EPOCHS]
                                   [--input_size INPUT_SIZE]
                                   [--learning_rate LEARNING_RATE]
                                   [--batch_size BATCH_SIZE]
                                   [--side {left,right}] [--mirror]
                                   [--head_type {direct_regression,simcc_1d,simcc_2d,simcc_2d_deconv}]
                                   [--split_ratio SPLIT_RATIO] [--sigma SIGMA]

options:
  -h, --help            show this help message and exit
  --data_dir DATA_DIR   Path to the dataset directory
  --model_name MODEL_NAME
                        Model name: 'efficientnet', 'resnet', or 'vgg'
  --epochs EPOCHS       Number of training epochs
  --input_size INPUT_SIZE
                        Input image size for the model
  --learning_rate LEARNING_RATE
                        Learning rate
  --batch_size BATCH_SIZE
                        Number of samples per batch
  --side {left,right}   Side to train on: 'left' or 'right'
  --mirror              Whether to include mirrored data from the opposite
                        side
  --head_type {direct_regression,simcc_1d,simcc_2d,simcc_2d_deconv}
                        Type of model head to use
  --split_ratio SPLIT_RATIO
                        SimCC split ratio for label encoding
  --sigma SIGMA         Sigma for SimCC label encoding
```

ç¯„ä¾‹åŸ·è¡Œï¼š
```
python3 train_hip_crop_keypoints.py --data_dir data --model_name convnext_small_custom --input_size 224 --epochs 200 --learning_rate 0.0001 --batch_size 32 --side left --mirror --head_type simcc_2d --split_ratio 3.0 --sigma 7.0
```

è¨“ç·´çµæœï¼š
- æœ€ä½³æ¨¡å‹æœƒå­˜ç‚ºï¼š
```
weights/{model_name}_{head_type}_{split_ratio}_{sigma}_{side}_{mirror}_{input_size}_{epochs}_{learning_rate}_{batch_size}_best.pth
```
ç¯„ä¾‹ï¼šconvnext_small_custom_simcc_2d_sr3.0_sigma7.0_cropleft_mirror_224_200_0.0001_32_best.pth 
- è¨“ç·´éç¨‹åœ–è¡¨æœƒå­˜ç‚ºï¼š
```
logs/{model_name}_{head_type}_{split_ratio}_{sigma}_{side}_{mirror}_{input_size}_{epochs}_{learning_rate}_{batch_size}_training_plot.png
```
ç¯„ä¾‹ï¼šconvnext_small_custom_simcc_2d_sr3.0_sigma7.0_cropleft_mirror_224_200_0.0001_32_training_plot.png
- è¨“ç·´æ—¥èªŒæœƒå­˜ç‚ºï¼š
```
logs/{model_name}_{head_type}_{split_ratio}_{sigma}_{side}_{mirror}_{input_size}_{epochs}_{learning_rate}_{batch_size}_training_log.txt
```
ç¯„ä¾‹ï¼šconvnext_small_custom_simcc_2d_sr3.0_sigma7.0_cropleft_mirror_224_200_0.0001_32_training_log.txt

### Evaluation

ä½¿ç”¨æ–¹å¼ï¼š
```
usage: predict_hip_crop_keypoints.py [-h] --model_name MODEL_NAME
                                     [--kp_left_path KP_LEFT_PATH]
                                     [--kp_right_path KP_RIGHT_PATH]
                                     --yolo_weights YOLO_WEIGHTS --data DATA
                                     [--output_dir OUTPUT_DIR]
                                     [--fold_index FOLD_INDEX]

options:
  -h, --help            show this help message and exit
  --model_name MODEL_NAME
                        efficientnet | resnet | vgg
  --kp_left_path KP_LEFT_PATH
                        left-side KP model (.pth)
  --kp_right_path KP_RIGHT_PATH
                        right-side KP model (.pth)
  --yolo_weights YOLO_WEIGHTS
                        YOLO weights (e.g., best.pt)
  --data DATA           data directory
  --output_dir OUTPUT_DIR
                        output directory
  --fold_index FOLD_INDEX
                        fold index for k-fold cross-validation (optional)
```
ç¯„ä¾‹åŸ·è¡Œï¼š
```
python3 predict_hip_crop_keypoints.py --model_name convnext_small_custom --kp_left_path weights/convnext_small_custom_simcc_2d_sr3.0_sigma7.0_cropleft_mirror_224_200_0.0001_32_best.pth --yolo_weights models/yolo12s.pt --data "data/test" --output_dir "results"
```

çµ±è¨ˆçµæœæœƒå­˜æ–¼ `{output_dir}` ç›®éŒ„ä¸­ã€‚
æ³¨æ„ï¼šè«‹ç¢ºä¿ç‰©ä»¶åµæ¸¬æ¬Šé‡ï¼ˆyolo_weightsï¼‰èˆ‡é—œéµé»æ¬Šé‡ï¼ˆkp_pathï¼‰çš†å·²è¨“ç·´å®Œæˆä¸¦å­˜åœ¨å°æ‡‰è·¯å¾‘ã€‚

## Usage-K-Fold Cross Validation

### Split Dataset

ä½¿ç”¨æ–¹å¼ï¼š
```
usage: kfold_split.py [-h] --src SRC --dst DST [--k K] [--seed SEED]
                      [--overwrite]

K-fold split for object detection and keypoint datasets

options:
  -h, --help   show this help message and exit
  --src SRC    Source directory containing images/, annotations/, detections/, yolo_labels/
  --dst DST    Destination directory where fold1..foldK and data_fold{i}.yaml will be created
  --k K        Number of folds
  --seed SEED  Random seed for shuffling
  --overwrite  If the destination directory exists, delete it before creating new folds
```
ç¯„ä¾‹åŸ·è¡Œï¼š
```
python kfold_split.py \
  --src dataset/xray_IHDI_6 \
  --dst data \
  --k 5 \
  --seed 42 \
  --overwrite
```

### Training

#### Step 1: Train YOLO Detector

ä½¿ç”¨æ–¹å¼ï¼š
```
python kfold_train_yolo.py \
  --model yolo12s.pt \
  --data_tpl data/data_fold{fold}.yaml \
  --k 5 \
  --epochs 300 --imgsz 640 --batch 8 --device 0 \
  --project runs/train --name yolo12s_kfold --pretrained --seed 42 \
  --fliplr 0.0 --flipud 0.0 --degrees 5.0 \
  --shear 0.0 --perspective 0.0 --mosaic 0.0 --mixup 0.0
```

#### Step 2: Train Keypoint Detector

ä½¿ç”¨æ–¹å¼ï¼š
```
usage: kfold_train_hip_crop_keypoints.py [-h] --data_root DATA_ROOT [--k K]
                                         [--mode {outer_inner,val_as_test}]
                                         [--inner_val_ratio INNER_VAL_RATIO]
                                         [--inner_seed INNER_SEED] [--copy]
                                         --model_name MODEL_NAME
                                         [--epochs EPOCHS]
                                         [--input_size INPUT_SIZE]
                                         [--learning_rate LEARNING_RATE]
                                         [--batch_size BATCH_SIZE]
                                         [--side {left,right}] [--mirror]
                                         [--head_type {direct_regression,simcc_1d,simcc_2d,simcc_2d_deconv}]
                                         [--split_ratio SPLIT_RATIO]
                                         [--sigma SIGMA]

K-fold training for hip crop keypoints.

options:
  -h, --help            show this help message and exit
  --data_root DATA_ROOT
                        åŒ…å« fold1..foldK çš„è³‡æ–™å¤¾ï¼Œä¾‹å¦‚ data æˆ–
                        dataset/xray_IHDI_5_kfold
  --k K                 fold æ•¸é‡
  --mode {outer_inner,val_as_test}
                        outer_inner = Outer K-fold + Inner split; val_as_test
                        = å–®å±¤ K-foldï¼Œval åŒæ™‚ä¹Ÿæ˜¯ä¹‹å¾Œçš„ test fold
  --inner_val_ratio INNER_VAL_RATIO
                        åœ¨ outer_inner æ¨¡å¼ä¸‹ï¼ŒTrain pool è£¡ç”¨å¤šå°‘æ¯”ä¾‹åš inner validation
  --inner_seed INNER_SEED
                        åœ¨ outer_inner æ¨¡å¼ä¸‹ï¼Œinner split çš„äº‚æ•¸ç¨®å­
  --copy                é è¨­ç”¨ symlink å»º tmp/train,valï¼›åŠ é€™å€‹å°±æ”¹æˆå¯¦éš›è¤‡è£½æª”æ¡ˆï¼ˆè¼ƒè€—ç©ºé–“ï¼‰
  --model_name MODEL_NAME
                        Model name: 'efficientnet', 'resnet', 'vgg',
                        'convnext' ç­‰
  --epochs EPOCHS
  --input_size INPUT_SIZE
  --learning_rate LEARNING_RATE
  --batch_size BATCH_SIZE
  --side {left,right}
  --mirror
  --head_type {direct_regression,simcc_1d,simcc_2d,simcc_2d_deconv}
  --split_ratio SPLIT_RATIO
                        SimCC çš„ sr åƒæ•¸ï¼Œç”¨åœ¨ head_type ç‚º simcc* æ™‚
  --sigma SIGMA         SimCC label encoding çš„ sigma
```
ç¯„ä¾‹åŸ·è¡Œï¼š
```
python kfold_train_hip_crop_keypoints.py \
  --data_root data \
  --k 5 \
  --mode outer_inner \
  --inner_val_ratio 0.1 \
  --inner_seed 42 \
  --model_name convnext_small_custom \
  --input_size 224 \
  --epochs 200 \
  --learning_rate 0.0001 \
  --batch_size 16 \
  --side left \
  --mirror \
  --head_type simcc_2d \
  --split_ratio 3.0 \
  --sigma 7.0
```

è¨“ç·´çµæœæœƒå­˜æ–¼ `weights/` ç›®éŒ„ä¸­ï¼Œæª”åæ ¼å¼å¦‚ä¸‹ï¼š
```
{model_name}_{head_type}_sr{split_ratio}_sigma{sigma}_crop{side}_{mirror}_{input_size}_{epochs}_{learning_rate}_{batch_size}_fold{fold}_best.pth
```

æ³¨æ„ï¼šè«‹ç¢ºä¿ data_root ç›®éŒ„ä¸­å·²åŒ…å« k-fold åˆ†å‰²å¾Œçš„è³‡æ–™å¤¾ï¼ˆfold1..foldKï¼‰èˆ‡å°æ‡‰çš„ data_fold{i}.yaml æª”æ¡ˆã€‚

### Evaluation

ä½¿ç”¨æ–¹å¼ï¼š
```
usage: kfold_predict_hip_crop_keypoints.py [-h] --model_name MODEL_NAME
                                           [--kp_left_tpl KP_LEFT_TPL]
                                           [--kp_right_tpl KP_RIGHT_TPL]
                                           --yolo_weights YOLO_WEIGHTS
                                           --data_root DATA_ROOT [--k K]
                                           [--output_root OUTPUT_ROOT]

K-fold test for hip crop keypoints.

options:
  -h, --help            show this help message and exit
  --model_name MODEL_NAME
                        efficientnet | resnet | vgg | convnext ...
  --kp_left_tpl KP_LEFT_TPL
                        å·¦å´ KP model è·¯å¾‘æ¨¡æ¿ï¼Œä¾‹å¦‚:
                        'weights/convnext_left_fold{fold}_best.pth'ï¼Œæœƒç”¨
                        .format(fold=i) ç”¢ç”Ÿæ¯å€‹ fold çš„è·¯å¾‘ã€‚
  --kp_right_tpl KP_RIGHT_TPL
                        å³å´ KP model è·¯å¾‘æ¨¡æ¿ï¼Œå¯ç•™ç©ºã€‚
  --yolo_weights YOLO_WEIGHTS
                        YOLO weights (e.g., weights/yolo12s_fold{fold}.pt)
  --data_root DATA_ROOT
                        åŒ…å« fold1, fold2, ... çš„è³‡æ–™å¤¾ï¼Œä¾‹å¦‚ data æˆ–
                        dataset/xray_IHDI_5_kfold
  --k K                 fold æ•¸é‡
  --output_root OUTPUT_ROOT
                        æ¯å€‹ fold çš„è¼¸å‡ºæ ¹ç›®éŒ„ï¼ˆä¸‹å±¤æœƒè‡ªå‹•å»ºç«‹ fold1, fold2, ...ï¼‰
```
ç¯„ä¾‹åŸ·è¡Œï¼š
```
python kfold_predict_hip_crop_keypoints.py \
  --model_name convnext_small_custom \
  --kp_left_tpl "weights/convnext_small_custom_simcc_2d_sr3.0_sigma7.0_cropleft_mirror_224_200_0.0001_16_fold{fold}_best.pth" \
  --yolo_weights weights/yolo12s_fold{fold}.pt \
  --data_root data \
  --k 5 \
  --output_root results_kfold
```

çµ±è¨ˆçµæœæœƒå­˜æ–¼ `{output_root}/{name}/fold{i}` ç›®éŒ„ä»¥åŠ`{output_root}/{name}/summary` è³‡æ–™å¤¾ä¸­
æ³¨æ„ï¼šè«‹ç¢ºä¿ç‰©ä»¶åµæ¸¬æ¬Šé‡ï¼ˆyolo_weightsï¼‰èˆ‡é—œéµé»æ¬Šé‡ï¼ˆkp_pathï¼‰çš†å·²è¨“ç·´å®Œæˆä¸¦å­˜åœ¨å°æ‡‰è·¯å¾‘ã€‚

## Inference

ğŸš§è‡¨åºŠä½¿ç”¨çš„ä»‹é¢æ­£åœ¨é–‹ç™¼ä¸­ğŸš§
ä½æ–¼ `Hip-Joint-Keypoint-Detection-Tool/` ç›®éŒ„ä¸‹çš„ç¨‹å¼ç¢¼ç‚ºå–®éšæ®µé—œéµé»åµæ¸¬ç³»çµ±çš„åˆæ­¥ä»‹é¢ï¼Œåƒ…ä¾›åƒè€ƒã€‚

## Results

ä¸åŒheadçš„å¯¦é©—çµæœï¼š
<img src="src/img/experiment.png" style="width: 80%;"/>

ä½¿ç”¨ ConvNeXtSmallCustom + SimCC 2D çš„æ¨¡å‹åœ¨ xray_IHDI è³‡æ–™é›†ä¸Šé€²è¡Œ 5-fold äº¤å‰é©—è­‰çš„çµæœå¦‚ä¸‹ï¼š

<img src="results_kfold/convnext_small_custom_simcc_2d_sr3.0_sigma7.0_left-only_224_200_0.0001_32/summary/all_avg_distances_hist.png" style="width: 49%;"/><img src="results_kfold/convnext_small_custom_simcc_2d_sr3.0_sigma7.0_left-only_224_200_0.0001_32/summary/all_ai_error_hist.png" style="width: 49%;"/>
<img src="results_kfold/convnext_small_custom_simcc_2d_sr3.0_sigma7.0_left-only_224_200_0.0001_32/summary/confusion_matrix_all.png" style="width: 49%;"/><img src="results_kfold/convnext_small_custom_simcc_2d_sr3.0_sigma7.0_left-only_224_200_0.0001_32/summary/scatter_overall_ai_angle.png" style="width: 49%;"/>

## References

- [SimCC](https://github.com/leeyegy/SimCC.git)
- [ConvNeXtV1](https://github.com/facebookresearch/ConvNeXt.git)
- [ConvNextV2](https://github.com/facebookresearch/ConvNeXt-V2.git)
- [EfficientNet](https://docs.pytorch.org/vision/main/models/efficientnet)
- [MambaVision](https://github.com/NVlabs/MambaVision.git)
- [InceptionNeXt](https://github.com/sail-sg/inceptionnext.git)
- [HRNet-Bottom-Up-Pose-Estimation](https://github.com/HRNet/HRNet-Bottom-Up-Pose-Estimation.git)
- [YOLO](https://docs.ultralytics.com/)

## Note

æ ¸å¿ƒæ¼”ç®—æ³•èˆ‡éƒ¨åˆ†é—œéµæŠ€è¡“ç´°ç¯€åŸºæ–¼ç ”ç©¶èˆ‡åˆä½œè€ƒé‡ï¼Œæš«ä¸å…¬é–‹ã€‚  
å¦‚å°æœ¬å°ˆæ¡ˆæœ‰èˆˆè¶£ï¼Œæ­¡è¿è¯çµ¡ä½œè€…æˆ–æ˜¯ç™¼é€ Issue é€²è¡Œè¨è«–ã€‚